# üß† Proyecto POC ‚Äî Segmentaci√≥n de Clientes con ML No Supervisado (K-Means)

Este proyecto corresponde a un **POC t√©cnico** orientado a identificar patrones de consumo en clientes del canal digital del organization, usando t√©cnicas de **aprendizaje no supervisado**, principalmente **K-Means**, con el objetivo de crear segmentos de clientes relevantes para **personalizaci√≥n de promociones** y **estrategias de marketing automatizadas**.

---

## üìÅ Estructura del Proyecto

- `/data/`: Datasets de entrada (consumos con tarjeta, ubicaci√≥n, productos, canal digital).
- `/outputs/`: Resultados del modelo (CSV con segmentos por cliente).
- `poc.ipynb`: Notebook principal con:
  - Exploraci√≥n de datos
  - Feature engineering
  - Entrenamiento y evaluaci√≥n de K-Means
  - Exportaci√≥n de resultados para backend

---

## üîç Objetivo T√©cnico

- Aplicar **K-Means** para descubrir grupos de clientes seg√∫n comportamiento transaccional.
- Generar un archivo `clientes_segmentados.csv` con:
  - `dni`
  - `cluster_id`
  - `cluster_nombre` (ej. "Farmacia", "Supermercado")
  - Scores por rubro
  - Fecha del modelo
- Dejar los resultados listos para **consumo por backend / app m√≥vil**.

---

## ‚öôÔ∏è Proceso T√©cnico

1. **Preprocesamiento**
   - Agrupaci√≥n por `dni` (cliente).
   - Transformaci√≥n de variables categ√≥ricas (`CanalTransaccion`, `Rubro`, etc.).
   - Generaci√≥n de features como:
     - Frecuencia de consumo por rubro
     - Monto promedio por rubro
     - Recencia (√∫ltima fecha de consumo)

2. **Modelo de Clustering**
   - Algoritmo: `KMeans` de `sklearn`
   - Selecci√≥n de n√∫mero de clusters usando m√©todo del codo (elbow method)
   - Entrenamiento del modelo sobre variables num√©ricas normalizadas (`StandardScaler`)

3. **Asignaci√≥n y exportaci√≥n**
   - Cada cliente recibe un `cluster_id`
   - Se genera un archivo CSV final con la siguiente estructura:

```csv
dni,cluster_id,cluster_nombre,rubro_top,score_supermercado,score_farmacia,score_restaurante,fecha_modelo
70457247,1,Farmacia,Farmacia,0.22,0.85,0.45,2024-08-07
...
```

4. **Carga del archivo**
   - Exportado en `/outputs/clientes_segmentados.csv`
   - Listo para carga en:
     - S3 / Blob Storage
     - Base de datos relacional
     - API backend para consumo por la app m√≥vil

---

## üìä Principales Hallazgos

- Se identificaron 3 clusters diferenciados:
  - üü© **Cluster 0:** clientes con mayor consumo en supermercados
  - üü¶ **Cluster 1:** comportamiento dominante en farmacias
  - üü• **Cluster 2:** clientes con gasto en restaurantes y delivery
- Estos segmentos permiten definir **campa√±as espec√≠ficas por grupo**, optimizando el targeting.

---

## üí° Casos de Uso T√©cnicos

| Use Case ML | Implementaci√≥n | Resultado Esperado |
|-------------|----------------|--------------------|
| Segmentaci√≥n por consumo | K-Means sobre features de rubro y monto | Archivo con cluster_id por cliente |
| Scoring por rubro | `groupby` + normalizaci√≥n de montos | Score por rubro como variable continua |
| Reentrenamiento autom√°tico | Parametrizable por Airflow / cron job | Actualizaci√≥n semanal del segmento |

---

## üì§ Output Listo para Backend

Formato entregado para integraci√≥n con sistemas del organization:

- Archivo `.csv` o `.parquet`
- Estructura legible por APIs o backend SQL
- Clave primaria: `dni`
- Particionado por fecha del modelo (`fecha_modelo`)

---

## üß© Recomendaciones de Escalabilidad

- Implementar **Soft Clustering (GMM)** si se requiere pertenencia parcial a m√∫ltiples rubros.
- Agregar feedback posterior de promociones como `label` para futuros modelos **supervisados**.
- Automatizar con pipelines en Airflow, Step Functions o similar.

---
```json
{
  "dni": "70457247",
  "cluster_id": 1,
  "cluster_nombre": "Farmacia",
  "rubro_top": "xyz",
  "score_supermercado": 0.22,
  "score_farmacia": 0.85,
  "score_restaurante": 0.45,
  "fecha_modelo": "2024-08-07"
}
```
---

## üõ†Ô∏è Tecnolog√≠as Usadas

- Python 3.11
- Pandas, NumPy, scikit-learn
- Matplotlib, Seaborn
- Jupyter Notebook
- (Opcional) Airflow / S3 / Parquet / APIs
