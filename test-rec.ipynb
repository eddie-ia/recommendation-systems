{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "168dbc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eddie.ml\\AppData\\Local\\Temp\\ipykernel_32560\\2746655191.py:39: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  return (ts.view(\"int64\") // 10**9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'rows': 5477922, 'users': 100890, 'items': 285, 'ts_min': 1719792000, 'ts_max': 1753833600, 'synth': 0.0}\n",
      "Final  : {'rows': 5477922, 'users': 100890, 'items': 285, 'ts_min': 1719792000, 'ts_max': 1753833600, 'synth': 0.0}\n",
      "\n",
      "Listo ‚úÖ\n",
      "MIN -> D:\\repos-eddie\\poc-recommendation-fb\\data\\personalize\\min\\interactions_mvp_validated.csv y schema_interactions.json\n",
      "OPT -> users_mvp_min.csv, items_mvp_min.csv, schema_users.json, schema_items.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, json\n",
    "from pathlib import Path\n",
    "\n",
    "# -------- Config m√≠nimos --------\n",
    "MIN_ROWS  = 1000\n",
    "MIN_USERS = 25\n",
    "MIN_ITEMS = 25\n",
    "BATCH_SIZE = 100  # tama√±o de bloque para \"agregar paulatinamente\"\n",
    "\n",
    "# -------- Helpers de rutas --------\n",
    "def find_dir_up(name: str, start: Path | None = None, max_up: int = 6) -> Path:\n",
    "    p = start or Path.cwd()\n",
    "    for _ in range(max_up + 1):\n",
    "        d = p / name\n",
    "        if d.is_dir():\n",
    "            return d.resolve()\n",
    "        p = p.parent\n",
    "    raise FileNotFoundError(f\"No se encontr√≥ ./{name} hacia arriba de {Path.cwd()}\")\n",
    "\n",
    "DATA = find_dir_up(\"data\")\n",
    "BASE = (DATA / \"personalize\"); BASE.mkdir(parents=True, exist_ok=True)\n",
    "MIN_DIR = (BASE / \"min\"); MIN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OPT_DIR = (BASE / \"opt\"); OPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------- Carga fuente --------\n",
    "src_csv  = DATA / \"data_consumos_tarjetas.csv\"\n",
    "src_xlsx = DATA / \"data_consumos_tarjetas.xlsx\"\n",
    "\n",
    "if src_csv.exists():\n",
    "    consumos = pd.read_csv(src_csv)\n",
    "elif src_xlsx.exists():\n",
    "    consumos = pd.read_excel(src_xlsx)\n",
    "else:\n",
    "    raise FileNotFoundError(\"No encuentro data_consumos_tarjetas.csv ni .xlsx en ./data\")\n",
    "\n",
    "# -------- Validaciones b√°sicas --------\n",
    "def to_epoch_col(series: pd.Series) -> pd.Series:\n",
    "    ts = pd.to_datetime(series, utc=True, errors=\"coerce\")\n",
    "    return (ts.view(\"int64\") // 10**9)\n",
    "\n",
    "def require(df, cols, name):\n",
    "    miss = [c for c in cols if c not in df.columns]\n",
    "    if miss:\n",
    "        raise ValueError(f\"{name}: faltan columnas {miss}\")\n",
    "\n",
    "require(consumos, [\"nro_documento\", \"Rubro\", \"fecha\"], \"data_consumos_tarjetas\")\n",
    "\n",
    "# -------- Construcci√≥n de interactions --------\n",
    "cols_opt = []\n",
    "if \"Monto\" in consumos.columns: cols_opt.append(\"AMOUNT\")\n",
    "if \"TipoTransaccion\" in consumos.columns: cols_opt.append(\"EVENT_TYPE\")\n",
    "\n",
    "interactions = consumos.rename(columns={\n",
    "    \"nro_documento\": \"USER_ID\",\n",
    "    \"Rubro\": \"ITEM_ID\",\n",
    "    \"fecha\": \"TIMESTAMP\",\n",
    "    \"Monto\": \"AMOUNT\",\n",
    "    \"TipoTransaccion\": \"EVENT_TYPE\",\n",
    "})[[\"USER_ID\",\"ITEM_ID\",\"TIMESTAMP\"] + cols_opt].copy()\n",
    "\n",
    "interactions[\"USER_ID\"]   = interactions[\"USER_ID\"].astype(str)\n",
    "interactions[\"ITEM_ID\"]   = interactions[\"ITEM_ID\"].astype(str)\n",
    "interactions[\"TIMESTAMP\"] = to_epoch_col(interactions[\"TIMESTAMP\"])\n",
    "\n",
    "if \"AMOUNT\" in interactions.columns:\n",
    "    interactions[\"AMOUNT\"] = pd.to_numeric(interactions[\"AMOUNT\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "# Limpieza y deduplicado\n",
    "interactions = interactions.dropna(subset=[\"USER_ID\",\"ITEM_ID\",\"TIMESTAMP\"])\n",
    "interactions = interactions.drop_duplicates(subset=[\"USER_ID\",\"ITEM_ID\",\"TIMESTAMP\"], keep=\"last\").copy()\n",
    "interactions[\"is_synth\"] = False\n",
    "\n",
    "def stats(df):\n",
    "    return dict(\n",
    "        rows=int(len(df)),\n",
    "        users=int(df[\"USER_ID\"].nunique() if len(df) else 0),\n",
    "        items=int(df[\"ITEM_ID\"].nunique() if len(df) else 0),\n",
    "        ts_min=int(df[\"TIMESTAMP\"].min()) if len(df) else None,\n",
    "        ts_max=int(df[\"TIMESTAMP\"].max()) if len(df) else None,\n",
    "        synth=float(df[\"is_synth\"].mean()) if \"is_synth\" in df.columns and len(df) else 0.0,\n",
    "    )\n",
    "\n",
    "initial = stats(interactions)\n",
    "\n",
    "# -------- ‚ÄúAgregar paulatinamente‚Äù si falta --------\n",
    "rng = np.random.default_rng(42)\n",
    "DEDUP_KEYS = [\"USER_ID\",\"ITEM_ID\",\"TIMESTAMP\"]\n",
    "\n",
    "def augment_batch(df: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    if df.empty: \n",
    "        return pd.DataFrame(columns=df.columns)\n",
    "    users = df[\"USER_ID\"].value_counts(normalize=True)\n",
    "    items = df[\"ITEM_ID\"].value_counts(normalize=True)\n",
    "    ts_min, ts_max = int(df[\"TIMESTAMP\"].min()), int(df[\"TIMESTAMP\"].max())\n",
    "\n",
    "    batch = pd.DataFrame({\n",
    "        \"USER_ID\": rng.choice(users.index, size=n, p=users.values, replace=True),\n",
    "        \"ITEM_ID\": rng.choice(items.index, size=n, p=items.values, replace=True),\n",
    "        \"TIMESTAMP\": rng.integers(ts_min, ts_max + 1, size=n, dtype=np.int64),\n",
    "        \"is_synth\": True\n",
    "    })\n",
    "\n",
    "    if \"AMOUNT\" in df.columns:\n",
    "        base = df[\"AMOUNT\"].dropna()\n",
    "        if len(base) == 0:\n",
    "            batch[\"AMOUNT\"] = 0.0\n",
    "        else:\n",
    "            sampled = rng.choice(base.values, size=n, replace=True)\n",
    "            noise = rng.normal(0.0, max(1.0, base.std(ddof=0) * 0.05), size=n)\n",
    "            batch[\"AMOUNT\"] = np.maximum(0.0, sampled + noise)\n",
    "\n",
    "    if \"EVENT_TYPE\" in df.columns:\n",
    "        base_evt = df[\"EVENT_TYPE\"].astype(str).fillna(\"event\")\n",
    "        vals, probs = np.unique(base_evt, return_counts=True)\n",
    "        probs = probs / probs.sum()\n",
    "        batch[\"EVENT_TYPE\"] = rng.choice(vals, size=n, p=probs, replace=True)\n",
    "\n",
    "    return batch.reindex(columns=df.columns).drop_duplicates(subset=DEDUP_KEYS)\n",
    "\n",
    "cur = interactions.copy()\n",
    "while (\n",
    "    (len(cur) < MIN_ROWS) or\n",
    "    (cur[\"USER_ID\"].nunique() < MIN_USERS) or\n",
    "    (cur[\"ITEM_ID\"].nunique() < MIN_ITEMS)\n",
    "):\n",
    "    add = augment_batch(cur, BATCH_SIZE)\n",
    "\n",
    "    # Forzar variedad si faltan uniques\n",
    "    if cur[\"USER_ID\"].nunique() < MIN_USERS and len(add):\n",
    "        need = MIN_USERS - cur[\"USER_ID\"].nunique()\n",
    "        base_users = cur[\"USER_ID\"].value_counts().index.tolist()[:max(1, need)]\n",
    "        for i in range(min(need, len(add))):\n",
    "            add.loc[add.index[i], \"USER_ID\"] = f\"{base_users[i % len(base_users)]}_new{rng.integers(1,10**6)}\"\n",
    "\n",
    "    if cur[\"ITEM_ID\"].nunique() < MIN_ITEMS and len(add):\n",
    "        need = MIN_ITEMS - cur[\"ITEM_ID\"].nunique()\n",
    "        base_items = cur[\"ITEM_ID\"].value_counts().index.tolist()[:max(1, need)]\n",
    "        for i in range(min(need, len(add))):\n",
    "            add.loc[add.index[i], \"ITEM_ID\"] = f\"{base_items[i % len(base_items)]}_alt{rng.integers(1,10**6)}\"\n",
    "\n",
    "    cur = pd.concat([cur, add], ignore_index=True)\n",
    "    cur = cur.drop_duplicates(subset=DEDUP_KEYS, keep=\"last\")\n",
    "\n",
    "# Orden y recorte (no eliminar reales)\n",
    "cur = cur.sort_values(\"TIMESTAMP\").reset_index(drop=True)\n",
    "target_rows = max(MIN_ROWS, len(interactions))\n",
    "if len(cur) > target_rows:\n",
    "    cur = cur.iloc[:target_rows].copy()\n",
    "\n",
    "final = stats(cur)\n",
    "\n",
    "# -------- Guardado MIN (obligatorio para Personalize) --------\n",
    "interactions_path = MIN_DIR / \"interactions_mvp_validated.csv\"\n",
    "cur.drop(columns=[\"is_synth\"]).to_csv(interactions_path, index=False)\n",
    "\n",
    "schema_interactions = {\n",
    "  \"type\": \"record\", \"name\": \"Interactions\",\n",
    "  \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "  \"fields\": [\n",
    "    {\"name\": \"USER_ID\", \"type\": \"string\"},\n",
    "    {\"name\": \"ITEM_ID\", \"type\": \"string\"},\n",
    "    {\"name\": \"TIMESTAMP\", \"type\": \"long\"},\n",
    "    {\"name\": \"AMOUNT\", \"type\": [\"null\",\"float\"], \"default\": None},\n",
    "    {\"name\": \"EVENT_TYPE\", \"type\": [\"null\",\"string\"], \"default\": None}\n",
    "  ],\n",
    "  \"version\": \"1.0\"\n",
    "}\n",
    "with open(MIN_DIR / \"schema_interactions.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(schema_interactions, f, indent=2)\n",
    "\n",
    "# -------- Guardado OPT (users/items opcionales) --------\n",
    "pd.DataFrame({\"USER_ID\": cur[\"USER_ID\"].unique()}).to_csv(OPT_DIR / \"users_mvp_min.csv\", index=False)\n",
    "pd.DataFrame({\n",
    "    \"ITEM_ID\": pd.unique(cur[\"ITEM_ID\"]),\n",
    "    \"title\":   pd.unique(cur[\"ITEM_ID\"]),\n",
    "    \"domain\":  [\"rubro\"] * cur[\"ITEM_ID\"].nunique()\n",
    "}).to_csv(OPT_DIR / \"items_mvp_min.csv\", index=False)\n",
    "\n",
    "schema_users = {\n",
    "  \"type\": \"record\", \"name\": \"Users\",\n",
    "  \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "  \"fields\": [\n",
    "    {\"name\": \"USER_ID\", \"type\": \"string\"},\n",
    "    {\"name\": \"segment\", \"type\": [\"null\",\"string\"], \"default\": None},\n",
    "    {\"name\": \"age\", \"type\": [\"null\",\"int\"], \"default\": None},\n",
    "    {\"name\": \"department\", \"type\": [\"null\",\"string\"], \"default\": None},\n",
    "    {\"name\": \"province\", \"type\": [\"null\",\"string\"], \"default\": None},\n",
    "    {\"name\": \"district\", \"type\": [\"null\",\"string\"], \"default\": None}\n",
    "  ],\n",
    "  \"version\": \"1.0\"\n",
    "}\n",
    "with open(OPT_DIR / \"schema_users.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(schema_users, f, indent=2)\n",
    "\n",
    "schema_items = {\n",
    "  \"type\": \"record\", \"name\": \"Items\",\n",
    "  \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "  \"fields\": [\n",
    "    {\"name\": \"ITEM_ID\", \"type\": \"string\"},\n",
    "    {\"name\": \"title\", \"type\": [\"null\",\"string\"], \"default\": None},\n",
    "    {\"name\": \"domain\", \"type\": [\"null\",\"string\"], \"default\": None}\n",
    "  ],\n",
    "  \"version\": \"1.0\"\n",
    "}\n",
    "with open(OPT_DIR / \"schema_items.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(schema_items, f, indent=2)\n",
    "\n",
    "# -------- Verificaci√≥n y assert de m√≠nimos --------\n",
    "print(\"Initial:\", initial)\n",
    "print(\"Final  :\", final)\n",
    "\n",
    "assert final[\"rows\"]  >= MIN_ROWS,  f\"rows {final['rows']} < {MIN_ROWS}\"\n",
    "assert final[\"users\"] >= MIN_USERS, f\"users {final['users']} < {MIN_USERS}\"\n",
    "assert final[\"items\"] >= MIN_ITEMS, f\"items {final['items']} < {MIN_ITEMS}\"\n",
    "\n",
    "print(\"\\nListo ‚úÖ\")\n",
    "print(\"MIN ->\", interactions_path, \"y schema_interactions.json\")\n",
    "print(\"OPT -> users_mvp_min.csv, items_mvp_min.csv, schema_users.json, schema_items.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ff23b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Shape: (5477922, 5)\n",
      "üß± Columnas: ['USER_ID', 'ITEM_ID', 'TIMESTAMP', 'AMOUNT', 'EVENT_TYPE']\n",
      "\n",
      "Primeras filas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>AMOUNT</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07548266</td>\n",
       "      <td>Supermercados, abarrotes</td>\n",
       "      <td>1719792000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Consumos Credito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46564290</td>\n",
       "      <td>Tiendas de productos varios</td>\n",
       "      <td>1719792000</td>\n",
       "      <td>19.3</td>\n",
       "      <td>Consumos Debito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46823325</td>\n",
       "      <td>Llamadas a trav√©s del uso de tel√©fonos de lect...</td>\n",
       "      <td>1719792000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Consumos Debito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46823325</td>\n",
       "      <td>Programaci√≥n de computadoras, procesamiento de...</td>\n",
       "      <td>1719792000</td>\n",
       "      <td>18.5</td>\n",
       "      <td>Consumos Debito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29535842</td>\n",
       "      <td>Supermercados, abarrotes</td>\n",
       "      <td>1719792000</td>\n",
       "      <td>20.9</td>\n",
       "      <td>Consumos Debito</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    USER_ID                                            ITEM_ID   TIMESTAMP  \\\n",
       "0  07548266                           Supermercados, abarrotes  1719792000   \n",
       "1  46564290                        Tiendas de productos varios  1719792000   \n",
       "2  46823325  Llamadas a trav√©s del uso de tel√©fonos de lect...  1719792000   \n",
       "3  46823325  Programaci√≥n de computadoras, procesamiento de...  1719792000   \n",
       "4  29535842                           Supermercados, abarrotes  1719792000   \n",
       "\n",
       "   AMOUNT        EVENT_TYPE  \n",
       "0    27.0  Consumos Credito  \n",
       "1    19.3   Consumos Debito  \n",
       "2     5.0   Consumos Debito  \n",
       "3    18.5   Consumos Debito  \n",
       "4    20.9   Consumos Debito  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Valores √∫nicos por campo (m√°x 10 muestras):\n",
      "\n",
      "USER_ID: 100890 √∫nicos\n",
      "Ejemplo: ['07548266' '46564290' '46823325' '29535842' '42860950' '73615200'\n",
      " '46805779' '25745599' '42214622' '42705582']\n",
      "\n",
      "ITEM_ID: 284 √∫nicos\n",
      "Ejemplo: ['Supermercados, abarrotes' 'Tiendas de productos varios'\n",
      " 'Llamadas a trav√©s del uso de tel√©fonos de lectura de banda magn√©tica.'\n",
      " 'Programaci√≥n de computadoras, procesamiento de datos, sistemas integrados y servicios de dise√±o'\n",
      " 'Tiendas de comida- almacenes y mercados especialidades.'\n",
      " 'Pagos de impuestos' 'Panader√≠as' 'Farmacias y boticas'\n",
      " 'Cargos de llamadas' 'Calzado comercial.']\n",
      "\n",
      "TIMESTAMP: 395 √∫nicos\n",
      "Ejemplo: [1719792000 1719878400 1719964800 1720051200 1720137600 1720224000\n",
      " 1720310400 1720396800 1720483200 1720569600]\n",
      "\n",
      "AMOUNT: 270977 √∫nicos\n",
      "Ejemplo: [27.  19.3  5.  18.5 20.9 20.7 14.3 20.  12.  82.9]\n",
      "\n",
      "EVENT_TYPE: 9 √∫nicos\n",
      "Ejemplo: ['Consumos Credito' 'Consumos Debito' 'Retiro' 'Consulta' 'Transferencia'\n",
      " 'Disposicion de Efectivo Debito' 'Compra Deuda'\n",
      " 'Disposicion de Efectivo Credito' 'Cambio de clave']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Ruta al archivo de la carpeta MIN\n",
    "path_csv = Path(\"data/personalize/min/interactions_mvp_validated.csv\")\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv(path_csv)\n",
    "\n",
    "# Mostrar informaci√≥n general\n",
    "print(\"üìä Shape:\", df.shape)\n",
    "print(\"üß± Columnas:\", df.columns.tolist())\n",
    "print(\"\\nPrimeras filas:\")\n",
    "display(df.head(5))\n",
    "\n",
    "# Mostrar valores √∫nicos por columna (solo hasta 10 para no saturar)\n",
    "print(\"\\nüîπ Valores √∫nicos por campo (m√°x 10 muestras):\")\n",
    "for col in df.columns:\n",
    "    uniques = df[col].dropna().unique()\n",
    "    sample = uniques[:10] if len(uniques) > 10 else uniques\n",
    "    print(f\"\\n{col}: {len(uniques)} √∫nicos\")\n",
    "    print(\"Ejemplo:\", sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6878e323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Listo: data\\personalize\\min\\interactions_mvp_filtered1000.csv\n",
      "rows: 1000 | users: 973 | items: 92 | event_types: 2\n",
      "Primeras filas:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eddie.ml\\AppData\\Local\\Temp\\ipykernel_32560\\2437337403.py:37: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(n=min(per, len(g)), random_state=rng))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>AMOUNT</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>40006125</td>\n",
       "      <td>Supermercados, abarrotes</td>\n",
       "      <td>1742601600</td>\n",
       "      <td>38.92</td>\n",
       "      <td>Consumos Debito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>40620726</td>\n",
       "      <td>Tiendas por departamento</td>\n",
       "      <td>1727654400</td>\n",
       "      <td>79.90</td>\n",
       "      <td>Consumos Debito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>40289830</td>\n",
       "      <td>Restaurantes y lugares para comer.</td>\n",
       "      <td>1726012800</td>\n",
       "      <td>40.00</td>\n",
       "      <td>Consumos Debito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>07624233</td>\n",
       "      <td>Tiendas por departamento</td>\n",
       "      <td>1736467200</td>\n",
       "      <td>80.33</td>\n",
       "      <td>Consumos Debito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>46121117</td>\n",
       "      <td>Ventas de seguros y primas</td>\n",
       "      <td>1742428800</td>\n",
       "      <td>107.49</td>\n",
       "      <td>Consumos Credito</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      USER_ID                             ITEM_ID   TIMESTAMP  AMOUNT  \\\n",
       "521  40006125            Supermercados, abarrotes  1742601600   38.92   \n",
       "737  40620726            Tiendas por departamento  1727654400   79.90   \n",
       "740  40289830  Restaurantes y lugares para comer.  1726012800   40.00   \n",
       "660  07624233            Tiendas por departamento  1736467200   80.33   \n",
       "411  46121117          Ventas de seguros y primas  1742428800  107.49   \n",
       "\n",
       "           EVENT_TYPE  \n",
       "521   Consumos Debito  \n",
       "737   Consumos Debito  \n",
       "740   Consumos Debito  \n",
       "660   Consumos Debito  \n",
       "411  Consumos Credito  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# --------- Config m√≠nima ----------\n",
    "SRC = Path(\"data/personalize/min/interactions_mvp_validated.csv\")\n",
    "DST = Path(\"data/personalize/min/interactions_mvp_filtered1000.csv\")\n",
    "TARGET_ROWS = 1000\n",
    "MIN_USERS = 25\n",
    "MIN_ITEMS = 25\n",
    "ALLOWED_EVENTS = {\"Consumos Credito\", \"Consumos Debito\"}  # ajusta si quieres\n",
    "\n",
    "# --------- Cargar ----------\n",
    "df = pd.read_csv(SRC)\n",
    "# Si existe EVENT_TYPE, filtra a los que aportan se√±al de consumo/pago\n",
    "if \"EVENT_TYPE\" in df.columns:\n",
    "    df = df[df[\"EVENT_TYPE\"].isin(ALLOWED_EVENTS)].copy()\n",
    "\n",
    "# Limpieza m√≠nima + unicidad por interacci√≥n\n",
    "df = df.dropna(subset=[\"USER_ID\",\"ITEM_ID\",\"TIMESTAMP\"])\n",
    "df = df.drop_duplicates(subset=[\"USER_ID\",\"ITEM_ID\",\"TIMESTAMP\"], keep=\"last\")\n",
    "\n",
    "# --------- Validar m√≠nimos de unicidad antes de muestrear ----------\n",
    "u_users = df[\"USER_ID\"].nunique()\n",
    "u_items = df[\"ITEM_ID\"].nunique()\n",
    "if u_users < MIN_USERS or u_items < MIN_ITEMS:\n",
    "    raise ValueError(f\"Despu√©s del filtro no se cumplen m√≠nimos: users={u_users} (>= {MIN_USERS}), items={u_items} (>= {MIN_ITEMS}).\")\n",
    "\n",
    "# --------- Muestreo a exactamente 1000 filas (estratificado simple) ----------\n",
    "# Preferimos balancear por EVENT_TYPE si existe; si no, muestreo aleatorio simple\n",
    "rng = 42\n",
    "if \"EVENT_TYPE\" in df.columns:\n",
    "    k = df[\"EVENT_TYPE\"].nunique()\n",
    "    per = max(1, TARGET_ROWS // k)\n",
    "    sample = (\n",
    "        df.groupby(\"EVENT_TYPE\", group_keys=False)\n",
    "          .apply(lambda g: g.sample(n=min(per, len(g)), random_state=rng))\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "    # completar si faltan filas\n",
    "    if len(sample) < TARGET_ROWS:\n",
    "        need = TARGET_ROWS - len(sample)\n",
    "        extra = df.drop(sample.index, errors=\"ignore\")\n",
    "        extra = extra.sample(n=min(need, len(extra)), random_state=rng)\n",
    "        sample = pd.concat([sample, extra], ignore_index=True)\n",
    "else:\n",
    "    sample = df.sample(n=min(TARGET_ROWS, len(df)), random_state=rng)\n",
    "\n",
    "# Si por alg√∫n motivo a√∫n falta, completar con aleatorio (sin reemplazo si se puede)\n",
    "if len(sample) < TARGET_ROWS and len(df) > len(sample):\n",
    "    need = TARGET_ROWS - len(sample)\n",
    "    extra = df.drop(sample.index).sample(n=min(need, len(df)-len(sample)), random_state=rng)\n",
    "    sample = pd.concat([sample, extra], ignore_index=True)\n",
    "\n",
    "# Si sobra (raro), recorta\n",
    "sample = sample.sample(n=TARGET_ROWS, random_state=rng) if len(sample) >= TARGET_ROWS else sample\n",
    "\n",
    "# --------- Validaciones finales ----------\n",
    "assert len(sample) == min(TARGET_ROWS, len(df)), f\"Filas={len(sample)}\"\n",
    "assert sample[\"USER_ID\"].nunique() >= MIN_USERS, \"No se cumple m√≠nimo de usuarios.\"\n",
    "assert sample[\"ITEM_ID\"].nunique() >= MIN_ITEMS, \"No se cumple m√≠nimo de √≠tems.\"\n",
    "\n",
    "# --------- Guardar ----------\n",
    "DST.parent.mkdir(parents=True, exist_ok=True)\n",
    "sample.to_csv(DST, index=False)\n",
    "\n",
    "print(\"‚úÖ Listo:\", DST)\n",
    "print(\"rows:\", len(sample),\n",
    "      \"| users:\", sample[\"USER_ID\"].nunique(),\n",
    "      \"| items:\", sample[\"ITEM_ID\"].nunique(),\n",
    "      \"| event_types:\", sample[\"EVENT_TYPE\"].nunique() if \"EVENT_TYPE\" in sample.columns else \"-\")\n",
    "print(\"Primeras filas:\")\n",
    "display(sample.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6977136a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
